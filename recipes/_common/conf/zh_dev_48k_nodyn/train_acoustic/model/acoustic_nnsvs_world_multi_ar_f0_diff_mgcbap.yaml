# This is a config file for a diffusion-based NNSVS's multi-stream acoustic model
# with WORLD-based acoustic features.
# NOTE: training is very slow but the trained model can achieve signifincatlly
# better naturalness compared to NNSVS-WORLD v4.
# NOTE: consider using larger batch size for training stability and longer training
# iteration to get better performance. Convergence is slower than the other models.
# NOTE: It is recommencded to try pre-training if you database does not
# have enough amount of data (> 1h).
# NOTE: in_ph_start_idx (start index of current-phoneme context) and
# in_ph_end_idx (end index of current-phoneme context) are hed-specific parameters
# and used for *optional* phoneme embedding (with embedding size of `embed_dim`).
# If you want to use this config with you hed file, there are two options:
#   1. Set `embed_dim` to null to disable phoneme embedding (the easiest way)
#   2. Find start and end indices of current-phoneme contexts in your hed file
#      and set them to `in_ph_start_idx` and `in_ph_end_idx` respectively.
# Using phoneme embedding may improve intelligiblity a little, but it is OK
# not to use it based on our experiments.
# Please carefully check hed-specific configurations.

# (mgc, lf0, vuv, bap)
stream_sizes: [60, 1, 1, 5]
has_dynamic_features: [false, false, false, false]
num_windows: 1
stream_weights:

netG:
  _target_: nnsvs.acoustic_models.NPSSMDNMultistreamParametricModel
  # The number of total input phonetic/musical context features.
  in_dim: 72 # NOTE: need to be changed for each hed file
  out_dim: 67

  # Must be set as the same as the above stream_sizes
  stream_sizes: [60, 1, 1, 5]
  # This is an imporant parameter to control the modeling capability of
  # autoregressive models. Don't change this unless if you are sure what you do.
  # The reduction factor of 4 was chosen empirecally.
  reduction_factor: 4

  # You MUST set in_rest_idx, in_lf0_idx and out_lf0_idx correctly
  # otherwise the model does't work at all.
  # Please configure your hed file so that in_rest_idx to be zero. i.e.,
  # put the sil-or-not phonetic context on the first item of your hed file.
  in_rest_idx: 0 # NOTE: need to be changed for each hed file
  in_lf0_idx: 62 # NOTE: need to be changed for each hed file
  out_lf0_idx: 60
  # Please leave the following parameters unspecified if you want to
  # find the corresponding values automatically from in/out scalers.
  in_lf0_min: null
  in_lf0_max: null
  out_lf0_mean: null
  out_lf0_scale: null

  # Flags to control conditioning features for V/UV prediction
  # If all true, [mgc, lf0, bap] are used for V/UV prediction.
  # IMPORTANT: not optimized yet
  vuv_model_bap_conditioning: false
  # if true, only 0-th dim of bap is used
  vuv_model_bap0_conditioning: false
  vuv_model_lf0_conditioning: true
  vuv_model_mgc_conditioning: true

  # A separate model for modeling continuous log-F0
  lf0_model:
    _target_: nnsvs.acoustic_models.BiLSTMResF0NonAttentiveDecoder
    # in_dim must be equal to netG.in_dim
    in_dim: 72 # NOTE: need to be changed for each hed file
    # out_dim must be equal to the dimension of log-F0
    out_dim: 1
    in_ph_start_idx: 1 # NOTE: need to be changed for each hed file
    in_ph_end_idx: 62 # NOTE: need to be changed for each hed file
    # set to null to disable phoneme embedding
    embed_dim: 256
    ff_hidden_dim: 256
    conv_hidden_dim: 128
    lstm_hidden_dim: 64
    num_lstm_layers: 2
    decoder_layers: 1
    decoder_hidden_dim: 256
    prenet_layers: 0
    prenet_hidden_dim: 16
    prenet_dropout: 0.5
    scaled_tanh: true
    zoneout: 0.0
    # This must be the same as netG.reduction_factor. Don't change
    reduction_factor: 4
    downsample_by_conv: true
    # This must be the same as netG.in_lf0_idx
    in_lf0_idx: 62 # NOTE: need to be changed for each hed file
    # This must be 0. Don't change
    out_lf0_idx: 0
    # OK to leave unspecified
    in_lf0_min: null
    in_lf0_max: null
    out_lf0_mean: null
    out_lf0_scale: null

  # Spectral parameter prediction model
  mgc_model:
    _target_: nnsvs.diffsinger.GaussianDiffusion
    in_dim: 73 # (x, lf0) # NOTE: need to be changed for each hed file
    out_dim: 60
    # The encoder processes the phonetic/musical contexts into hidden representations
    encoder:
       _target_: nnsvs.model.FFConvLSTM
       # This must be equal to netG.mgc_model.in_dim
       in_dim: 73 # (x, lf0) # NOTE: need to be changed for each hed file
       in_ph_start_idx: 1 # NOTE: need to be changed for each hed file
       in_ph_end_idx: 62 # NOTE: need to be changed for each hed file
       embed_dim: 256
       ff_hidden_dim: 512
       conv_hidden_dim: 256
       lstm_hidden_dim: 128
       num_lstm_layers: 2
       bidirectional: true
       dropout: 0.0
       out_dim: 256
    K_step: 100
    betas: null
    # Beta scheduler
    schedule_type: linear
    scheduler_params:
      max_beta: 0.06
    # Denoiser (noise -> output features)
    denoise_fn:
      _target_: nnsvs.diffsinger.DiffNet
      # in_dim must be equal to netG.mgc_model.out_dim
      in_dim: 60
      encoder_hidden_dim: 256
      residual_layers: 20
      residual_channels: 256
      dilation_cycle_length: 4

  # Aperiodic parameter prediction model
  bap_model:
    _target_: nnsvs.diffsinger.GaussianDiffusion
    in_dim: 73 # (x, lf0) # NOTE: need to be changed for each hed file
    out_dim: 5
    # Parameter to convert mean-var normalized data (~ N(0, 1)) to [-1, 1].
    # may need to adjust in 5 to 10.
    # assuming that the absolute maximum value of the normalized data is smaller than
    # `norm_scale` so the data (~ N(0,1); 99.9% are in [-norm_scale, norm_scale]) is
    # property scaled to [-1, 1]
    norm_scale: 10
    # The encoder processes the phonetic/musical contexts into hidden representations
    encoder:
       _target_: nnsvs.model.FFConvLSTM
       # This must be equal to netG.bap_model.in_dim
       in_dim: 73 # (x, lf0) # NOTE: need to be changed for each hed file
       in_ph_start_idx: 1 # NOTE: need to be changed for each hed file
       in_ph_end_idx: 62 # NOTE: need to be changed for each hed file
       embed_dim: 256
       ff_hidden_dim: 256
       conv_hidden_dim: 128
       lstm_hidden_dim: 64
       num_lstm_layers: 2
       bidirectional: true
       dropout: 0.0
       out_dim: 128
    K_step: 100
    betas: null
    # Beta scheduler
    schedule_type: linear
    scheduler_params:
      max_beta: 0.06
    # Denoiser (noise -> output features)
    denoise_fn:
      _target_: nnsvs.diffsinger.DiffNet
      # in_dim must be equal to netG.bap_model.out_dim
      in_dim: 5
      encoder_hidden_dim: 128
      residual_layers: 10
      residual_channels: 128
      dilation_cycle_length: 4

  # V/UV prediction model
  vuv_model:
    _target_: nnsvs.model.FFConvLSTM
    in_dim: 133 # (x, lf0, mgc) # NOTE: need to be changed for each hed file
    in_ph_start_idx: 1 # NOTE: need to be changed for each hed file
    in_ph_end_idx: 62 # NOTE: need to be changed for each hed file
    embed_dim: 256
    ff_hidden_dim: 256
    conv_hidden_dim: 128
    lstm_hidden_dim: 64
    num_lstm_layers: 2
    bidirectional: true
    out_dim: 1
    dropout: 0.1
    init_type: "kaiming_normal"
